{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9aL21skm6K-"
      },
      "source": [
        "### Clone GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LT_cukaNouM8"
      },
      "outputs": [],
      "source": [
        "!rm -rf ML-Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YtdoXtCjZX-",
        "outputId": "f4f3074b-cb1a-4a21-c81f-1f7d83a34b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML-Project'...\n",
            "remote: Enumerating objects: 1656, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n"
          ]
        }
      ],
      "source": [
        "REPO_URL = \"https://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@github.com/aleexx02/ML-Project.git\"\n",
        "!git clone $REPO_URL\n",
        "%cd ML-Project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPcZ89fjnBWv"
      },
      "source": [
        "### Imports and Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rC-EjZBrj26q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import copy\n",
        "import json\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "PROJECT_ROOT = \".\"\n",
        "DATA_DIR = os.path.join(PROJECT_ROOT, \"BDMA7_project_files\")\n",
        "\n",
        "TRAIN_IMAGES_DIR = os.path.join(DATA_DIR, \"train_images\")\n",
        "VAL_IMAGES_DIR   = os.path.join(DATA_DIR, \"val_images\")\n",
        "TEST_IMAGES_DIR  = os.path.join(DATA_DIR, \"test_images\", \"mistery_cat\")\n",
        "\n",
        "TRAIN_META_PATH = os.path.join(DATA_DIR, \"train_metadata.csv\")\n",
        "VAL_META_PATH   = os.path.join(DATA_DIR, \"val_metadata.csv\")\n",
        "SAMPLE_SUB_PATH = os.path.join(DATA_DIR, \"sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQaM4gnHcw_Y"
      },
      "source": [
        "### Weights and Biases Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QX7-aym9ursr"
      },
      "outputs": [],
      "source": [
        "# Uncomment to install wandb\n",
        "# !pip install wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2CxBwI8eu1Lf"
      },
      "outputs": [],
      "source": [
        "# import wandb\n",
        "# wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKUFXIrUq1jF"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6xyUSU_aq4Mz"
      },
      "outputs": [],
      "source": [
        "# PARAMETERS FOR MODEL\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 20\n",
        "IMG_SIZE = 224\n",
        "NUM_WORKERS = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbf-3wD0n0lG"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQbVhIkx0fTw"
      },
      "source": [
        "* **Training dataset**: with flips, to have variety and make a stronger model: model learns more than one orientation of a same bird: *(image_tensor, label)*.\n",
        "\n",
        "* **Evaluation dataset**: without flips. *(image_tensor, label)*.\n",
        "\n",
        "* **Testing dataset**: *(image_tensor, path)*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tUvjRBCAnwIp"
      },
      "outputs": [],
      "source": [
        "# Load metadata for train, eval and test\n",
        "train_meta = pd.read_csv(TRAIN_META_PATH)\n",
        "val_meta   = pd.read_csv(VAL_META_PATH)\n",
        "test_meta = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "\n",
        "train_meta[\"images_dir\"] = TRAIN_IMAGES_DIR\n",
        "val_meta[\"images_dir\"] = VAL_IMAGES_DIR\n",
        "\n",
        "\n",
        "train_meta = train_meta[[\"path\", \"class_idx\", \"images_dir\"]]\n",
        "val_meta = val_meta[[\"path\", \"class_idx\", \"images_dir\"]]\n",
        "\n",
        "print(train_meta.head())\n",
        "print(train_meta.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5lDQ8vDfwRt0"
      },
      "outputs": [],
      "source": [
        "# Generate the datasets\n",
        "class BirdsDataset(Dataset):\n",
        "    def __init__(self, df, images_dir, transform=None, has_labels=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.images_dir = images_dir\n",
        "        self.transform = transform\n",
        "        self.has_labels = has_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    # given id, get (image_tensor, label) of the corresponding image.\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        try:\n",
        "            base_dir = row[\"images_dir\"] if \"images_dir\" in self.df.columns else self.images_dir\n",
        "            img_path = os.path.join(base_dir, row[\"path\"])\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "            if self.transform is not None:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            if self.has_labels:\n",
        "                return image, int(row[\"class_idx\"])\n",
        "            else:\n",
        "                return image, row[\"path\"]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"\\n DATA ERROR idx =\", idx)\n",
        "            print(\"row index keys:\", list(row.index))\n",
        "            print(\"row:\", row)\n",
        "            print(\"base_dir:\", base_dir if \"base_dir\" in locals() else None)\n",
        "            print(\"img_path:\", img_path if \"img_path\" in locals() else None)\n",
        "            raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPAGeVQVfMuy"
      },
      "source": [
        "##### Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OMl2_bq1fQXf"
      },
      "outputs": [],
      "source": [
        "# Transform the training and evaluation datasets:\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(5),\n",
        "    transforms.ColorJitter(brightness=0.05, contrast=0.6, saturation=0.15, hue=0.01),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "# We don't flip the evaluation images\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaxpXRQnwWVO"
      },
      "source": [
        "##### Cross validation set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "moqq8Vn8wrNG"
      },
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=8,shuffle=True,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hp2fnTbBxeFR"
      },
      "outputs": [],
      "source": [
        "full_meta = pd.concat([train_meta, val_meta], ignore_index=True).copy()\n",
        "full_meta[\"images_dir\"] = full_meta[\"images_dir\"].astype(str)\n",
        "full_meta[\"path\"] = full_meta[\"path\"].astype(str)\n",
        "full_meta[\"full_path\"] = full_meta[\"images_dir\"].str.rstrip(\"/\") + \"/\" + full_meta[\"path\"].str.lstrip(\"/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a2FFy97qouNC"
      },
      "outputs": [],
      "source": [
        "# Create datasets for sampling purposes (not for training)\n",
        "train_dataset = BirdsDataset(train_meta, TRAIN_IMAGES_DIR, train_transform, has_labels=True)\n",
        "eval_dataset = BirdsDataset(val_meta, VAL_IMAGES_DIR, val_test_transform, has_labels=True)\n",
        "test_dataset = BirdsDataset(test_meta, TEST_IMAGES_DIR, val_test_transform, has_labels=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O81sfspBbye5"
      },
      "outputs": [],
      "source": [
        "def make_loader(df, transform, shuffle, has_labels = True):\n",
        "    dataset = BirdsDataset(df, images_dir = None, transform=transform, has_labels=has_labels)\n",
        "    return DataLoader(dataset,batch_size=BATCH_SIZE,shuffle=shuffle, num_workers=NUM_WORKERS, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG4d0vEfhJ3a"
      },
      "source": [
        "##### Distribution of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BH31cDo1-IDc"
      },
      "outputs": [],
      "source": [
        "idx_to_name = {\n",
        "    0: 'Groove_billed_Ani', 1: 'Red_winged_Blackbird', 2: 'Rusty_Blackbird',\n",
        "    3: 'Gray_Catbird', 4: 'Brandt_Cormorant', 5: 'Eastern_Towhee',\n",
        "    6: 'Indigo_Bunting', 7: 'Brewer_Blackbird', 8: 'Painted_Bunting',\n",
        "    9: 'Bobolink', 10: 'Lazuli_Bunting', 11: 'Yellow_headed_Blackbird',\n",
        "    12: 'American_Crow', 13: 'Fish_Crow', 14: 'Brown_Creeper',\n",
        "    15: 'Yellow_billed_Cuckoo', 16: 'Yellow_breasted_Chat',\n",
        "    17: 'Black_billed_Cuckoo', 18: 'Gray_crowned_Rosy_Finch',\n",
        "    19: 'Bronzed_Cowbird'\n",
        "}\n",
        "\n",
        "train_dist = train_meta[\"class_idx\"].value_counts().sort_index()\n",
        "val_dist = val_meta[\"class_idx\"].value_counts().sort_index()\n",
        "\n",
        "# DataFrames\n",
        "train_df = pd.DataFrame({\n",
        "    'Class_ID': train_dist.index,\n",
        "    'Class_Name': [idx_to_name[i] for i in train_dist.index],\n",
        "    'Train_Count': train_dist.values\n",
        "})\n",
        "\n",
        "val_df = pd.DataFrame({\n",
        "    'Class_ID': val_dist.index,\n",
        "    'Class_Name': [idx_to_name[i] for i in val_dist.index],\n",
        "    'Val_Count': val_dist.values\n",
        "})\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    'Class_ID': list(range(20)),\n",
        "    'Class_Name': [idx_to_name[i] for i in range(20)],\n",
        "    'Test_Count': '?'\n",
        "})\n",
        "\n",
        "print(\"=\"* 50)\n",
        "print(\"            Training Distribution\")\n",
        "print(\"=\"* 50)\n",
        "print(train_df.to_markdown(index=False))\n",
        "\n",
        "print(\"=\"* 50)\n",
        "print(\"            Validation Distribution\")\n",
        "print(\"=\"* 50)\n",
        "print(val_df.to_markdown(index=False))\n",
        "\n",
        "print(\"=\"* 50)\n",
        "print(\"            Test Distribution\")\n",
        "print(\"=\"* 50)\n",
        "print(test_df.to_markdown(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NuhytBnkouNE"
      },
      "outputs": [],
      "source": [
        "class_counts = full_meta[\"class_idx\"].value_counts().sort_index()\n",
        "\n",
        "class_names = [idx_to_name[i] for i in class_counts.index]\n",
        "\n",
        "plt.figure(figsize=(14,7))\n",
        "plt.bar(class_names, class_counts.values)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count of birds\")\n",
        "plt.title(\"distrubution of the dataset\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P61koEWq-528"
      },
      "source": [
        "##### Show some samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIlBOL0Q_Css"
      },
      "outputs": [],
      "source": [
        "def show_random_samples(dataset, num_samples=4, title=\"Samples\"):\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
        "\n",
        "    # Get random indices\n",
        "    indices = torch.randperm(len(dataset))[:num_samples].numpy()\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        image, label = dataset[idx]\n",
        "\n",
        "        image = image * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "        image = image + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "        image = torch.clamp(image, 0, 1)\n",
        "\n",
        "        axes[i].imshow(image.permute(1, 2, 0).numpy())\n",
        "        axes[i].set_title(f\"Class {label}\", fontsize=14)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Show samples for train, evaluation and test\n",
        "print(\"TRAINING samples:\")\n",
        "show_random_samples(train_dataset, title= \"Training Dataset\")\n",
        "\n",
        "print(\"\\nVALIDATION samples:\")\n",
        "show_random_samples(eval_dataset, title=\"Validation Dataset\")\n",
        "\n",
        "print(\"\\nTESTING samples:\")\n",
        "show_random_samples(test_dataset, title=\"Testing Dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YTIQpuCC08A"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wW8k5h-bn77D"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import convnext_small, ConvNeXt_Small_Weights\n",
        "\n",
        "class ConvNeXtBirds(nn.Module):\n",
        "    def __init__(self, num_classes=20, dropout=0.25, pretrained=True, mlp_depth=1, mlp_hidden=512, mlp_ratio=0.5, use_layernorm=True):\n",
        "\n",
        "        super().__init__()\n",
        "        weights = ConvNeXt_Small_Weights.DEFAULT if pretrained else None\n",
        "        self.backbone = convnext_small(weights=weights)\n",
        "\n",
        "        in_features = self.backbone.classifier[-1].in_features\n",
        "\n",
        "        layers = [nn.Flatten(1), nn.LayerNorm(in_features)]\n",
        "\n",
        "        # when depth = 1 -> Dropout + Linear output\n",
        "        if mlp_depth == 1:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            layers.append(nn.Linear(in_features, num_classes))\n",
        "\n",
        "        # when depth > 1 -> (depth-1) hidden + output\n",
        "        else:\n",
        "            prev = in_features\n",
        "            hidden = mlp_hidden\n",
        "\n",
        "            # hidden layers: (mlp_depth - 1)\n",
        "            for i in range(mlp_depth - 1):\n",
        "                layers.append(nn.Linear(prev, hidden))\n",
        "                layers.append(nn.GELU())\n",
        "                if use_layernorm:\n",
        "                    layers.append(nn.LayerNorm(hidden))\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "\n",
        "                prev = hidden\n",
        "                hidden = max(64, int(hidden * mlp_ratio))\n",
        "\n",
        "            layers.append(nn.Linear(prev, num_classes))\n",
        "\n",
        "        self.backbone.classifier = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTZOlNKowgzT"
      },
      "source": [
        "### GRID SEARCH using the Weights and Biases Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM7F4nsnjqkc"
      },
      "source": [
        "##### Settle the sweep configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i-Ix3q5vwjTF"
      },
      "outputs": [],
      "source": [
        "# Uncomment to settle the sweep configuration for grid search\n",
        "\n",
        "# # Sweep Configuration: what hyperparameters to tune\n",
        "# sweep_config = {\n",
        "#     'method': 'bayes',\n",
        "#     'name': 'convnext-bird-hyperparameter-search',\n",
        "#     'metric': {\n",
        "#         'name': 'mean_fold_accuracy',  # what we want to maximize\n",
        "#         'goal': 'maximize'\n",
        "#     },\n",
        "#     'parameters': {\n",
        "#         # Hyperparameters to tune:\n",
        "\n",
        "#         'dropout': {\n",
        "#             'values': [0.15, 0.20, 0.25, 0.30]\n",
        "#         },\n",
        "\n",
        "#         'learning_rate': {\n",
        "#             'values': [7.5e-5, 1e-4, 1.5e-4, 2e-4, 3e-4, 4e-4]\n",
        "#         },\n",
        "\n",
        "#         'batch_size': {\n",
        "#             'values': [32, 64]\n",
        "#         },\n",
        "\n",
        "#         'frozen_epochs': {\n",
        "#             'values': [10, 15, 20, 25]\n",
        "#         },\n",
        "\n",
        "#         'finetune_epochs': {\n",
        "#             'values': [0, 5, 10]\n",
        "#         },\n",
        "\n",
        "#         'weight_decay': {\n",
        "#             'values': [0.0, 0.001, 0.005, 0.01]\n",
        "#         },\n",
        "\n",
        "#         'rotation_degrees': {\n",
        "#             'values': [15, 30]\n",
        "#         },\n",
        "\n",
        "#         'color_jitter_strength': {\n",
        "#             'values': [0.1, 0.2, 0.3]\n",
        "#         },\n",
        "\n",
        "#         'n_folds': {\n",
        "#             'value': 8\n",
        "#         },\n",
        "\n",
        "#         'mlp_depth': {'values': [1, 2, 3]},\n",
        "#         'mlp_hidden': {'values': [256, 512, 1024]},\n",
        "#         'mlp_ratio': {'values': [0.5, 0.75]},\n",
        "#         'use_layernorm': {'values': [True]},\n",
        "\n",
        "#         'num_classes': {\n",
        "#             'value': 20\n",
        "#         },\n",
        "\n",
        "#         'img_size': {\n",
        "#             'value': 224\n",
        "#         },\n",
        "\n",
        "#         'num_workers': {\n",
        "#             'value': 4\n",
        "#         },\n",
        "#         'scheduler_type': {\n",
        "#           'values': ['plateau', 'cosine']\n",
        "#         },\n",
        "\n",
        "#         # per plateau\n",
        "#         'plateau_factor': {'values': [0.5]},\n",
        "#         'plateau_patience_frozen': {'values': [2, 3]},\n",
        "#         'plateau_patience_finetune': {'values': [1, 2]},\n",
        "\n",
        "#         # per cosine\n",
        "#         'cosine_tmax_frozen': {'values': [20, 30, 40]},\n",
        "#         'cosine_tmax_finetune': {'values': [5, 10]},\n",
        "#         'cosine_eta_min': {'values': [1e-6, 1e-5]},\n",
        "#             }\n",
        "# }\n",
        "\n",
        "# # Initializing the sweep\n",
        "# sweep_id = wandb.sweep(sweep_config, project=\"bird-classification-sweep\")\n",
        "\n",
        "# print(f\"Access to dashboard at: https://wandb.ai/alexandraperruchot/bird-classification-sweep/sweeps/{sweep_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flg09Wxkjij4"
      },
      "source": [
        "##### Training with sweep configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GGiBr_O2xHb"
      },
      "outputs": [],
      "source": [
        "# Uncomment to define the function for training with sweep configuration\n",
        "\n",
        "# def train_with_sweep_config():\n",
        "#     with wandb.init() as run:\n",
        "#         config = wandb.config\n",
        "#         run_id = run.id\n",
        "#         timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "#         hp_tag = (\n",
        "#             f\"dp{config.dropout}_lr{config.learning_rate:.1e}_bs{config.batch_size}\"\n",
        "#             f\"_fd{config.frozen_epochs}_ft{config.finetune_epochs}\"\n",
        "#             f\"_mlpD{config.mlp_depth}_H{config.mlp_hidden}_r{config.mlp_ratio}\"\n",
        "#         )\n",
        "\n",
        "#         base_ckpt_dir = f\"checkpoints/sweep_{timestamp}_{run_id}_{hp_tag}\"\n",
        "#         os.makedirs(base_ckpt_dir, exist_ok=True)\n",
        "\n",
        "#         print(f\"\\n Checkpoints directory for this run: {base_ckpt_dir}\\n\")\n",
        "#         print(f\"\\n{'='*70}\")\n",
        "#         print(f\"TRAINING WITH HYPERPARAMETERS:\")\n",
        "#         print(f\"{'='*70}\")\n",
        "#         print(f\"  Dropout:          {config.dropout}\")\n",
        "#         print(f\"  Learning Rate:    {config.learning_rate:.6f}\")\n",
        "#         print(f\"  Batch Size:       {config.batch_size}\")\n",
        "#         print(f\"  Frozen Epochs:    {config.frozen_epochs}\")\n",
        "#         print(f\"  Finetune Epochs:  {config.finetune_epochs}\")\n",
        "#         print(f\"  Weight Decay:     {config.weight_decay}\")\n",
        "#         print(f\"  Rotation:         {config.rotation_degrees}°\")\n",
        "#         print(f\"  Color Jitter:     {config.color_jitter_strength}\")\n",
        "#         print(f\"  N Folds:          {config.n_folds}\")\n",
        "#         print(f\"{'='*70}\\n\")\n",
        "\n",
        "#         # Create data transforms with sweep config\n",
        "#         train_transform = transforms.Compose([\n",
        "#             transforms.Resize((config.img_size, config.img_size)),\n",
        "#             transforms.RandomHorizontalFlip(p=0.5),\n",
        "#             transforms.RandomRotation(degrees=config.rotation_degrees),\n",
        "#             transforms.ColorJitter(\n",
        "#                 brightness=config.color_jitter_strength,\n",
        "#                 contrast=config.color_jitter_strength,\n",
        "#                 saturation=config.color_jitter_strength,\n",
        "#                 hue=config.color_jitter_strength * 0.5\n",
        "#             ),\n",
        "#             transforms.ToTensor(),\n",
        "#             transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "#         ])\n",
        "\n",
        "#         # Validation transform (no augmentation)\n",
        "#         val_test_transform = transforms.Compose([\n",
        "#             transforms.Resize((config.img_size, config.img_size)),\n",
        "#             transforms.ToTensor(),\n",
        "#             transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "#         ])\n",
        "\n",
        "#         # Cross validation setup\n",
        "#         fold_models = []\n",
        "#         fold_accuracies = []\n",
        "#         fold_histories = []\n",
        "\n",
        "#         skf = StratifiedKFold(n_splits=config.n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "#         # Cross validation loop\n",
        "#         for fold, (train_idx, val_idx) in enumerate(skf.split(full_meta, full_meta[\"class_idx\"])):\n",
        "#             print(f\"\\n{'='*50}\")\n",
        "#             print(f\" Fold {fold+1}/{config.n_folds}\")\n",
        "#             print(f\"{'='*50}\")\n",
        "\n",
        "#             # split data\n",
        "#             train_df = full_meta.iloc[train_idx].reset_index(drop=True)\n",
        "#             val_df = full_meta.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "#             # Create data loaders\n",
        "#             train_dataset = BirdsDataset(train_df, images_dir=None, transform=train_transform, has_labels=True)\n",
        "#             val_dataset = BirdsDataset(val_df, images_dir=None, transform=val_test_transform, has_labels=True)\n",
        "\n",
        "#             train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
        "\n",
        "#             val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
        "\n",
        "#             print(f\"Train images: {len(train_df)} | Val images: {len(val_df)}\")\n",
        "\n",
        "#             # Create model with sweep config\n",
        "#             model = ConvNeXtBirds(num_classes=config.num_classes, dropout=config.dropout, pretrained=True, mlp_depth=config.mlp_depth, mlp_hidden=config.mlp_hidden, mlp_ratio=config.mlp_ratio, use_layernorm=config.use_layernorm).to(device)\n",
        "\n",
        "#             # we freeze backbone initially\n",
        "#             for p in model.backbone.features.parameters():\n",
        "#                 p.requires_grad = False\n",
        "#             for p in model.backbone.classifier.parameters():\n",
        "#                 p.requires_grad = True\n",
        "\n",
        "#             # optimizer with sweep config\n",
        "#             optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
        "\n",
        "#             criterion = nn.CrossEntropyLoss()\n",
        "#             if config.scheduler_type == \"plateau\":\n",
        "#               scheduler = ReduceLROnPlateau(optimizer, mode=\"max\", factor=config.plateau_factor, patience=config.plateau_patience_frozen)\n",
        "#             elif config.scheduler_type == \"cosine\":\n",
        "#                 scheduler = CosineAnnealingLR(optimizer, T_max=config.cosine_tmax_frozen, eta_min=config.cosine_eta_min)\n",
        "#             else:\n",
        "#                 raise ValueError(f\"Unknown scheduler_type: {config.scheduler_type}\")\n",
        "\n",
        "#             # keeping track of training metrics\n",
        "#             best_acc = 0.0\n",
        "#             best_model_path = os.path.join(base_ckpt_dir, f\"best_fold_{fold+1}.pth\")\n",
        "#             history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "\n",
        "#             # ========== FROZEN TRAINING ==========\n",
        "#             print(f\"\\nFrozen Training ({config.frozen_epochs} epochs)\")\n",
        "\n",
        "#             for epoch in range(config.frozen_epochs):\n",
        "#                 print(f\"\\nEpoch {epoch+1}/{config.frozen_epochs} (Frozen)\")\n",
        "\n",
        "#                 train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "#                 val_loss, val_acc = validate_one_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "#                 history[\"train_loss\"].append(train_loss)\n",
        "#                 history[\"val_loss\"].append(val_loss)\n",
        "#                 history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "#                 print(f\"Train: {train_acc:.1f}% (Loss: {train_loss:.3f})\")\n",
        "#                 print(f\"Val:   {val_acc:.1f}% (Loss: {val_loss:.3f}) | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "#                 # we save the best model\n",
        "#                 if val_acc > best_acc:\n",
        "#                     best_acc = val_acc\n",
        "\n",
        "#                     torch.save(model.state_dict(), best_model_path)\n",
        "#                     print(f\"New best accuracy! Saved to {best_model_path}\")\n",
        "\n",
        "#                 if config.scheduler_type == \"plateau\":\n",
        "#                     scheduler.step(val_acc)\n",
        "#                 else:\n",
        "#                     scheduler.step()\n",
        "\n",
        "#                 # Log\n",
        "#                 wandb.log({\n",
        "#                     f\"fold_{fold+1}/train_loss\": train_loss,\n",
        "#                     f\"fold_{fold+1}/train_acc\": train_acc,\n",
        "#                     f\"fold_{fold+1}/val_loss\": val_loss,\n",
        "#                     f\"fold_{fold+1}/val_acc\": val_acc,\n",
        "#                     f\"fold_{fold+1}/learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "#                     \"epoch\": epoch,\n",
        "#                     \"fold\": fold + 1,\n",
        "#                     \"phase\": \"frozen\"\n",
        "#                 })\n",
        "\n",
        "#             # ========== FINE-TUNING ==========\n",
        "#             if config.finetune_epochs > 0:\n",
        "#                 print(f\"\\nFine-tuning ({config.finetune_epochs} epochs)\")\n",
        "\n",
        "#                 # Unfreeze all layers\n",
        "#                 for p in model.parameters():\n",
        "#                     p.requires_grad = True\n",
        "\n",
        "#                 # new optimizer with lower learning rate\n",
        "#                 optimizer = AdamW(model.parameters(), lr=config.learning_rate * 0.1, weight_decay=config.weight_decay)\n",
        "#                 scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "#                 for epoch in range(config.finetune_epochs):\n",
        "#                     print(f\"\\nEpoch {epoch+1}/{config.finetune_epochs} (Fine-tuning)\")\n",
        "\n",
        "#                     train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "#                     val_loss, val_acc = validate_one_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "#                     history[\"train_loss\"].append(train_loss)\n",
        "#                     history[\"val_loss\"].append(val_loss)\n",
        "#                     history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "#                     print(f\"Train: {train_acc:.1f}% (Loss: {train_loss:.3f})\")\n",
        "#                     print(f\"Val:   {val_acc:.1f}% (Loss: {val_loss:.3f}) | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "#                     # Save if better\n",
        "#                     if val_acc > best_acc:\n",
        "#                         best_acc = val_acc\n",
        "#                         torch.save(model.state_dict(), best_model_path)\n",
        "#                         print(f\" New best accuracy! Saved to {best_model_path}\")\n",
        "\n",
        "#                     scheduler.step(val_acc)\n",
        "\n",
        "#                     # Log\n",
        "#                     wandb.log({\n",
        "#                         f\"fold_{fold+1}/finetune_train_loss\": train_loss,\n",
        "#                         f\"fold_{fold+1}/finetune_train_acc\": train_acc,\n",
        "#                         f\"fold_{fold+1}/finetune_val_loss\": val_loss,\n",
        "#                         f\"fold_{fold+1}/finetune_val_acc\": val_acc,\n",
        "#                         f\"fold_{fold+1}/learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "#                         \"epoch\": config.frozen_epochs + epoch,\n",
        "#                         \"fold\": fold + 1,\n",
        "#                         \"phase\": \"finetune\"\n",
        "#                     })\n",
        "\n",
        "#             # store fold results\n",
        "#             fold_accuracies.append(best_acc)\n",
        "#             fold_models.append(best_model_path)\n",
        "#             fold_histories.append(history)\n",
        "\n",
        "#             # Log\n",
        "#             wandb.log({\n",
        "#                 f\"fold_{fold+1}/best_val_accuracy\": best_acc,\n",
        "#             })\n",
        "\n",
        "#             print(f\"\\n Fold {fold+1} Complete - Best Accuracy: {best_acc:.2f}%\")\n",
        "\n",
        "#             # Clean up before next fold\n",
        "#             del model, optimizer, scheduler, train_loader, val_loader\n",
        "#             torch.cuda.empty_cache()\n",
        "\n",
        "#         # ========== SUMMARY STATISTICS ==========\n",
        "#         mean_accuracy = np.mean(fold_accuracies)\n",
        "#         std_accuracy  = np.std(fold_accuracies)\n",
        "#         best_fold     = np.max(fold_accuracies)\n",
        "#         worst_fold    = np.min(fold_accuracies)\n",
        "\n",
        "#         summary = {\n",
        "#             \"run_id\": run_id,\n",
        "#             \"timestamp\": timestamp,\n",
        "#             \"mean_accuracy\": float(mean_accuracy),\n",
        "#             \"std_accuracy\": float(std_accuracy),\n",
        "#             \"best_fold_accuracy\": float(best_fold),\n",
        "#             \"worst_fold_accuracy\": float(worst_fold),\n",
        "#             \"fold_accuracies\": [float(x) for x in fold_accuracies],\n",
        "#             \"fold_models\": fold_models,\n",
        "#             \"hyperparameters\": {\n",
        "#                 k: (v if isinstance(v, (int, float, str, bool)) else str(v))\n",
        "#                 for k, v in dict(config).items()\n",
        "#             },\n",
        "#         }\n",
        "\n",
        "#         with open(os.path.join(base_ckpt_dir, \"summary.json\"), \"w\") as f:\n",
        "#             json.dump(summary, f, indent=2)\n",
        "\n",
        "#         with open(os.path.join(base_ckpt_dir, \"README.txt\"), \"w\") as f:\n",
        "#             f.write(\"RUN SUMMARY\\n\")\n",
        "#             f.write(f\"run_id: {run_id}\\n\")\n",
        "#             f.write(f\"timestamp: {timestamp}\\n\")\n",
        "#             f.write(f\"mean_accuracy: {mean_accuracy:.4f}\\n\")\n",
        "#             f.write(f\"std_accuracy: {std_accuracy:.4f}\\n\")\n",
        "#             f.write(f\"best_fold_accuracy: {best_fold:.4f}\\n\")\n",
        "#             f.write(f\"worst_fold_accuracy: {worst_fold:.4f}\\n\\n\")\n",
        "#             f.write(\"FOLD ACCURACIES:\\n\")\n",
        "#             for i, acc in enumerate(fold_accuracies, 1):\n",
        "#                 f.write(f\"  fold_{i}: {acc:.4f}\\n\")\n",
        "#             f.write(\"\\nHYPERPARAMETERS:\\n\")\n",
        "#             for k, v in dict(config).items():\n",
        "#                 f.write(f\"  {k}: {v}\\n\")\n",
        "\n",
        "#         final_dir = f\"{base_ckpt_dir}_mean{mean_accuracy:.4f}\"\n",
        "#         os.rename(base_ckpt_dir, final_dir)\n",
        "\n",
        "\n",
        "#         fold_models = [p.replace(base_ckpt_dir, final_dir) for p in fold_models]\n",
        "\n",
        "#         print(f\"Summary statistics saved: {os.path.join(final_dir, 'summary.json')}\")\n",
        "\n",
        "#         summary[\"fold_models\"] = fold_models\n",
        "#         with open(os.path.join(final_dir, \"summary.json\"), \"w\") as f:\n",
        "#             json.dump(summary, f, indent=2)\n",
        "\n",
        "#         print(f\"\\n{'='*70}\")\n",
        "#         print(f\"CROSS-VALIDATION RESULTS:\")\n",
        "#         print(f\"{'='*70}\")\n",
        "#         print(f\"  Mean Accuracy:  {mean_accuracy:.2f}% ± {std_accuracy:.2f}%\")\n",
        "#         print(f\"  Best Fold:      {best_fold:.2f}%\")\n",
        "#         print(f\"  Worst Fold:     {worst_fold:.2f}%\")\n",
        "#         print(f\"  All Folds:      {[f'{acc:.2f}%' for acc in fold_accuracies]}\")\n",
        "#         print(f\"{'='*70}\\n\")\n",
        "\n",
        "#         wandb.log({\n",
        "#             \"mean_fold_accuracy\": mean_accuracy,\n",
        "#             \"std_fold_accuracy\": std_accuracy,\n",
        "#             \"best_fold_accuracy\": best_fold,\n",
        "#             \"worst_fold_accuracy\": worst_fold,\n",
        "#         })\n",
        "\n",
        "#         fold_table = wandb.Table(\n",
        "#             columns=[\"Fold\", \"Validation Accuracy\", \"Model Path\"],\n",
        "#             data=[[i+1, acc, path] for i, (acc, path) in enumerate(zip(fold_accuracies, fold_models))]\n",
        "#         )\n",
        "#         wandb.log({\"fold_results_table\": fold_table})\n",
        "\n",
        "#         return mean_accuracy, fold_accuracies, fold_models, fold_histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pccHOAh_3IrP"
      },
      "outputs": [],
      "source": [
        "# Uncomment to start the grid search\n",
        "\n",
        "# wandb.agent(sweep_id, function=train_with_sweep_config, count=15)\n",
        "\n",
        "# print(\"\\n\" + \"=\"*70)\n",
        "# print(\"GRID SEARCH COMPLETED!\")\n",
        "# print(\"=\"*70)\n",
        "# print(f\"\\nView results of the grid search in the dashboard: https://wandb.ai/alexandraperruchot/bird-classification-sweep/sweeps/{sweep_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV94G2ybEFQZ"
      },
      "source": [
        "### Optimal Parameters\n",
        "\n",
        "After grid search we came up with the following optimal parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSxvIrqYEDT7"
      },
      "outputs": [],
      "source": [
        "OPTIMAL_PARAMS = {\n",
        "    'learning_rate': 0.0002,\n",
        "    'weight_decay': 0.001,\n",
        "    'batch_size': 32,\n",
        "    'dropout': 0.3,\n",
        "    'frozen_epochs': 25,\n",
        "    'finetune_epochs': 10,\n",
        "    'mlp_depth': 3,\n",
        "    'mlp_hidden': 1024,\n",
        "    'mlp_ratio': 0.5,\n",
        "    'rotation_degrees': 30,\n",
        "    'color_jitter_strength': 0.1,\n",
        "    'scheduler_type': 'plateau',\n",
        "    'plateau_factor': 0.5,\n",
        "    'plateau_patience_frozen': 2,\n",
        "    'plateau_patience_finetune': 1,\n",
        "}\n",
        "\n",
        "\n",
        "# Setup data transformations with the optimal parameters\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=OPTIMAL_PARAMS['rotation_degrees']),\n",
        "    transforms.ColorJitter(\n",
        "        brightness=OPTIMAL_PARAMS['color_jitter_strength'],\n",
        "        contrast=OPTIMAL_PARAMS['color_jitter_strength'],\n",
        "        saturation=OPTIMAL_PARAMS['color_jitter_strength'],\n",
        "        hue=OPTIMAL_PARAMS['color_jitter_strength'] * 0.5\n",
        "    ),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2v-isfB65BI"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    # we initialize variables for loss and accuracy\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # progress bar to show training progress\n",
        "    pbar = tqdm(train_loader, desc=\"Training\")\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        # move data to device\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        # update statistics\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # update progress bar\n",
        "        pbar.set_postfix({\"Loss\": f\"{loss.item():.3f}\", \"Acc\": f\"{100.*correct/total:.1f}%\"})\n",
        "\n",
        "    # return epoch metrics (optional)\n",
        "    train_acc = 100.*correct/total\n",
        "    return train_loss/ len(train_loader), train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfo3TzDc7USF"
      },
      "outputs": [],
      "source": [
        "def validate_one_epoch(model, val_loader, criterion, device):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # initialize variables for loss and accuracy\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # progress bar to show validation progress\n",
        "    pbar = tqdm(val_loader, desc=\"Validating\")\n",
        "    with torch.no_grad():\n",
        "      for images, labels in pbar:\n",
        "          # move data to device\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "          # forward pass\n",
        "          outputs = model(images)\n",
        "\n",
        "          # compute validation loss\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # update statistics\n",
        "          val_loss += loss.item()\n",
        "          _, predicted = outputs.max(1)\n",
        "          total += labels.size(0)\n",
        "          correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "          pbar.set_postfix({\"Loss\": f\"{loss.item():.3f}\", \"Acc\": f\"{100.*correct/total:.1f}%\"})\n",
        "\n",
        "    val_acc = 100. * correct / total\n",
        "\n",
        "    # return validation metrics\n",
        "    return val_loss/len(val_loader), val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jskPsZpb9d7"
      },
      "source": [
        "### Cross-validation loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymcwd1mEE720"
      },
      "outputs": [],
      "source": [
        "fold_models = []\n",
        "fold_accuracies = []\n",
        "all_histories = []\n",
        "\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(full_meta, full_meta['class_idx']), 1):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"FOLD {fold}/{8}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # split data\n",
        "    train_fold_df = full_meta.iloc[train_idx].reset_index(drop=True)\n",
        "    val_fold_df = full_meta.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    print(f\"Train: {len(train_fold_df)} | Val: {len(val_fold_df)}\")\n",
        "\n",
        "    # create datasets\n",
        "    train_dataset = BirdsDataset(train_fold_df, images_dir=TRAIN_IMAGES_DIR, transform=train_transform, has_labels=True)\n",
        "    val_dataset = BirdsDataset(val_fold_df, images_dir=TRAIN_IMAGES_DIR, transform=val_test_transform, has_labels=True)\n",
        "\n",
        "    # create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=OPTIMAL_PARAMS['batch_size'], shuffle=True, num_workers=NUM_WORKERS)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=OPTIMAL_PARAMS['batch_size'], shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "    # create model with optimal parameters\n",
        "    model = ConvNeXtBirds(num_classes=NUM_CLASSES, dropout=OPTIMAL_PARAMS['dropout'], pretrained=True, mlp_depth=OPTIMAL_PARAMS['mlp_depth'], mlp_hidden=OPTIMAL_PARAMS['mlp_hidden'], mlp_ratio=OPTIMAL_PARAMS['mlp_ratio'], use_layernorm=True).to(device)\n",
        "\n",
        "    # ==========FROZEN BACKBONE ==========\n",
        "    print(f\"\\nFrozen backbone ({OPTIMAL_PARAMS['frozen_epochs']} epochs)\")\n",
        "\n",
        "    # freeze backbone\n",
        "    for p in model.backbone.features.parameters():\n",
        "        p.requires_grad = False\n",
        "    for p in model.backbone.classifier.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "    # optimizer and scheduler\n",
        "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=OPTIMAL_PARAMS['learning_rate'], weight_decay=OPTIMAL_PARAMS['weight_decay'])\n",
        "\n",
        "    if OPTIMAL_PARAMS['scheduler_type'] == 'plateau':\n",
        "        scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=OPTIMAL_PARAMS['plateau_factor'], patience=OPTIMAL_PARAMS['plateau_patience_frozen'])\n",
        "    else:  # cosine\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=OPTIMAL_PARAMS.get('cosine_tmax_frozen', 30), eta_min=OPTIMAL_PARAMS.get('cosine_eta_min', 1e-6))\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    best_acc = 0.0\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "    # Train frozen\n",
        "    for epoch in range(OPTIMAL_PARAMS['frozen_epochs']):\n",
        "        print(f\"\\nEpoch {epoch+1}/{OPTIMAL_PARAMS['frozen_epochs']} (Frozen)\")\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_acc = validate_one_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"Train: {train_acc:.1f}% (Loss: {train_loss:.3f})\")\n",
        "        print(f\"Val: {val_acc:.1f}% (Loss: {val_loss:.3f})\")\n",
        "\n",
        "        # we update scheduler\n",
        "        if OPTIMAL_PARAMS['scheduler_type'] == 'plateau':\n",
        "            scheduler.step(val_acc)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "        # save best model\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), f'best_model_fold{fold}.pth')\n",
        "            print(f\"Saved best model: {best_acc:.2f}%\")\n",
        "\n",
        "\n",
        "    # ========== FINETUNE ==========\n",
        "    if OPTIMAL_PARAMS['finetune_epochs'] > 0:\n",
        "        print(f\"\\nFinetuning ({OPTIMAL_PARAMS['finetune_epochs']} epochs)\")\n",
        "\n",
        "        # unfreeze all\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "        # mew optimizer with lower LR\n",
        "        optimizer = AdamW(model.parameters(), lr=OPTIMAL_PARAMS['learning_rate'] * 0.1,weight_decay=OPTIMAL_PARAMS['weight_decay'])\n",
        "        scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "        # train finetune\n",
        "        for epoch in range(OPTIMAL_PARAMS['finetune_epochs']):\n",
        "            print(f\"\\nEpoch {epoch+1}/{OPTIMAL_PARAMS['finetune_epochs']} (Finetune)\")\n",
        "\n",
        "            train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "            val_loss, val_acc = validate_one_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['train_acc'].append(train_acc)\n",
        "            history['val_loss'].append(val_loss)\n",
        "            history['val_acc'].append(val_acc)\n",
        "\n",
        "            print(f\"Train: {train_acc:.1f}% (Loss: {train_loss:.3f})\")\n",
        "            print(f\"Val: {val_acc:.1f}% (Loss: {val_loss:.3f})\")\n",
        "\n",
        "            scheduler.step(val_acc)\n",
        "\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save(model.state_dict(), f'best_model_fold{fold}.pth')\n",
        "                print(f\"Saved best model: {best_acc:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"\\n Fold {fold} Best Accuracy: {best_acc:.2f}%\")\n",
        "    fold_models.append(f'best_model_fold{fold}.pth')\n",
        "    fold_accuracies.append(best_acc)\n",
        "    all_histories.append(history)\n",
        "\n",
        "\n",
        "    # clean-up\n",
        "    del model, train_loader, val_loader\n",
        "    torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWO4MR6gBVqY"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE - CROSS-VALIDATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# show accuracy of each fold\n",
        "for fold_num, acc in enumerate(fold_accuracies, 1):\n",
        "    print(f\"Fold {fold_num}: {acc:.2f}%\")\n",
        "\n",
        "mean_acc = np.mean(fold_accuracies)\n",
        "std_acc = np.std(fold_accuracies)\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(f\"Mean Fold Accuracy: {mean_acc:.2f}%\")\n",
        "print(f\"Standard Deviation: {std_acc:.2f}%\")\n",
        "print(\"-\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmgg50PK6uhi"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GezV59wG5m9y"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def predict_logits_tta(model, images):\n",
        "    # get predictions from original images\n",
        "    logits1 = model(images)\n",
        "    # get predictions from horizontally flipped images\n",
        "    logits2 = model(torch.flip(images, dims=[3]))\n",
        "    # return average of both predictions\n",
        "    return (logits1 + logits2) / 2.0\n",
        "\n",
        "def predict_test_ensemble_tta_mean_logits(model_paths, test_loader, device, model_fn, num_classes, dropout, use_amp=True):\n",
        "    all_paths = None\n",
        "    logits_sum = None\n",
        "    K = len(model_paths)\n",
        "\n",
        "    for mp in model_paths:\n",
        "        print(f\"\\nLoading model: {mp}\")\n",
        "        # create model architecture (without pretrained weights)\n",
        "        model = model_fn(\n",
        "            num_classes=num_classes,\n",
        "            dropout=dropout,\n",
        "            pretrained=False,\n",
        "            mlp_depth=OPTIMAL_PARAMS[\"mlp_depth\"],\n",
        "            mlp_hidden=OPTIMAL_PARAMS[\"mlp_hidden\"],\n",
        "            mlp_ratio=OPTIMAL_PARAMS[\"mlp_ratio\"],\n",
        "            use_layernorm=True,\n",
        "        ).to(device)\n",
        "\n",
        "        # load trained weights from this fold\n",
        "        state = torch.load(mp, map_location=device)\n",
        "        model.load_state_dict(state)\n",
        "        model.eval()\n",
        "\n",
        "        fold_logits = []\n",
        "        fold_paths = []\n",
        "\n",
        "        # predict on the test dataset\n",
        "        for images, paths in tqdm(test_loader, desc=f\"Predicting {mp}\"):\n",
        "            images = images.to(device)\n",
        "\n",
        "            if use_amp and device.type == \"cuda\":\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    logits = predict_logits_tta(model, images)\n",
        "            else:\n",
        "                logits = predict_logits_tta(model, images)\n",
        "            # store predictions and paths\n",
        "            fold_logits.append(logits.detach().cpu().numpy())\n",
        "            fold_paths.extend(list(paths))\n",
        "\n",
        "        fold_logits = np.concatenate(fold_logits, axis=0)\n",
        "\n",
        "        if all_paths is None:\n",
        "            all_paths = fold_paths\n",
        "        else:\n",
        "            assert fold_paths == all_paths, (\"ERROR: order mismatch!\")\n",
        "\n",
        "        # accumulate logits across models\n",
        "        if logits_sum is None:\n",
        "            logits_sum = fold_logits\n",
        "        else:\n",
        "            logits_sum += fold_logits\n",
        "\n",
        "        # free memory after this model\n",
        "        del model\n",
        "        if device.type == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # compute ensemble predictions\n",
        "    mean_logits = logits_sum / K\n",
        "\n",
        "    preds = mean_logits.argmax(axis=1)\n",
        "\n",
        "    # extract image filenames\n",
        "    jpg_regex = re.compile(r\".+\\.jpg$\", re.IGNORECASE)\n",
        "    image_ids = []\n",
        "    for p in all_paths:\n",
        "        filename = p.split(\"/\")[-1]\n",
        "        if jpg_regex.match(filename):\n",
        "            image_ids.append(filename)\n",
        "        else:\n",
        "            raise ValueError(f\"error file wrong .jpg: {filename}\")\n",
        "    # return predictions, filenames and mean logits\n",
        "    return preds, image_ids, mean_logits\n",
        "\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"GENERATING TEST PREDICTIONS (MEAN LOGITS, NO WEIGHTS, TTA)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# create test dataLoader\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "preds, image_ids, mean_logits = predict_test_ensemble_tta_mean_logits(\n",
        "    model_paths=fold_models,\n",
        "    test_loader=test_loader,\n",
        "    device=device,\n",
        "    model_fn=ConvNeXtBirds,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    dropout=OPTIMAL_PARAMS[\"dropout\"],\n",
        "    use_amp=True\n",
        ")\n",
        "\n",
        "\n",
        "df_final = pd.DataFrame({\n",
        "    \"path\": image_ids,\n",
        "    \"class_idx\": preds,\n",
        "})\n",
        "\n",
        "# export predicitons to a .csv file\n",
        "out_csv = \"/content/ML-Project/test_ConvNext_Layers.csv\"\n",
        "df_final.to_csv(out_csv, index=False)\n",
        "\n",
        "print(f\"\\n Saved: {out_csv}\")\n",
        "print(df_final.head(10))\n",
        "print(\"Total predictions:\", len(df_final))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}